{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "파인튜닝을 위한 코드이다. 이미 존재하는 모델에 추가 데이터를 투입하여 파라미터를 업데이트를 위한 코드이다."
      ],
      "metadata": {
        "id": "_63KiWDAJRnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1. 구글 드라이브를 코랩에 연결한다.**\n",
        "> 이는 추후 모델을 불러오고, 학습할 데이터를 불러오기 위해 필요한 과정이다. \\\n",
        " 따라서 이 코드를 실행하기 전에, 구글 드라이브에 모델과 토크나이저, 전처리된 데이터를 업로드 해야 한다."
      ],
      "metadata": {
        "id": "WF-eA4rJkdep"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vkt_udVIoCJC",
        "outputId": "a56c904b-8d59-4ad6-9694-1737d0a0b1a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2. 파인튜닝을 위해 필요한 라이브러리를 불러온다.**"
      ],
      "metadata": {
        "id": "2VdfRFOzjL4B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-6NGKQfC3WI",
        "outputId": "9a8879e2-fdd9-4ab6-8b8b-2a4308a629c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: seqeval[gpu] in /usr/local/lib/python3.8/dist-packages (1.2.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval[gpu]) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers seqeval[gpu]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "969yCCDOC3WS",
        "outputId": "558b75c0-a875-4920-d67a-89f2ce9c1003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n",
            "Requirement already satisfied: torch==1.10.2+cu113 in /usr/local/lib/python3.8/dist-packages (1.10.2+cu113)\n",
            "Requirement already satisfied: torchvision==0.11.3+cu113 in /usr/local/lib/python3.8/dist-packages (0.11.3+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.10.2+cu113) (4.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.11.3+cu113) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.11.3+cu113) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.10.2+cu113 torchvision==0.11.3+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF7__pf1C3WW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import ElectraTokenizerFast, ElectraConfig, ElectraForTokenClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXDLb7DVC3WZ"
      },
      "outputs": [],
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3. 파인튜닝을 위한 데이터셋을 불러온다.**\n",
        "> ***데이터의 경로 입력/수정 필수!***"
      ],
      "metadata": {
        "id": "QpdMQhznVGCj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "EvPgbiYHC3Wc",
        "outputId": "195ef941-9d99-48c9-8ee9-e575e6bda098"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  1. 오이와 대파는 5cm길이로 채를 썬 후 대파는 찬물에 담가주세요. 청상추는 한...   \n",
              "1  2. 차돌박이는 키친타올에 올려 핏물을 제거해주세요. 볼에 양념 재료를 넣어 섞어주세요.   \n",
              "2  4. 흐르는 찬물에 중면을 여러 번 씻어 전분기를 없애고, 채반에 받쳐 물기를 빼주세요.   \n",
              "3                 5. 달군 팬에 차돌박이를 소금간을 하여 노릇하게 구워주세요.   \n",
              "4  6. 섞어둔 양념장에 중면을 넣고 고루 버무려주세요. 청상추를 넣어 가볍게 버무려주세요.   \n",
              "\n",
              "                                               label  \n",
              "0  O O CV_INGREDIENT O CV_INGREDIENT O O O O O O ...  \n",
              "1  O O CV_INGREDIENT CV_INGREDIENT CV_INGREDIENT ...  \n",
              "2  O O O O O O CV_INGREDIENT CV_INGREDIENT O O O ...  \n",
              "3  O O O O O O CV_INGREDIENT CV_INGREDIENT CV_ING...  \n",
              "4  O O CV_STATE CV_STATE CV_STATE CV_SEASONING CV...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b087889-2008-4c13-92d1-0f1eaa712f4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1. 오이와 대파는 5cm길이로 채를 썬 후 대파는 찬물에 담가주세요. 청상추는 한...</td>\n",
              "      <td>O O CV_INGREDIENT O CV_INGREDIENT O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2. 차돌박이는 키친타올에 올려 핏물을 제거해주세요. 볼에 양념 재료를 넣어 섞어주세요.</td>\n",
              "      <td>O O CV_INGREDIENT CV_INGREDIENT CV_INGREDIENT ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4. 흐르는 찬물에 중면을 여러 번 씻어 전분기를 없애고, 채반에 받쳐 물기를 빼주세요.</td>\n",
              "      <td>O O O O O O CV_INGREDIENT CV_INGREDIENT O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5. 달군 팬에 차돌박이를 소금간을 하여 노릇하게 구워주세요.</td>\n",
              "      <td>O O O O O O CV_INGREDIENT CV_INGREDIENT CV_ING...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6. 섞어둔 양념장에 중면을 넣고 고루 버무려주세요. 청상추를 넣어 가볍게 버무려주세요.</td>\n",
              "      <td>O O CV_STATE CV_STATE CV_STATE CV_SEASONING CV...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b087889-2008-4c13-92d1-0f1eaa712f4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b087889-2008-4c13-92d1-0f1eaa712f4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b087889-2008-4c13-92d1-0f1eaa712f4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/2022_lesik_workspace/lesik/data/total+yejib_train.tsv', sep = '\\t', keep_default_na=False)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "태그는 최근 모델과 동일해야 되므로 변경해서는 안된다."
      ],
      "metadata": {
        "id": "vUBdq-4wgmjn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_CDSb4AZ0C5",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Split labels based on whitespace and turn them into a list\n",
        "arr_labels = set()\n",
        "for lb in df.label:\n",
        "    lb = lb.split()\n",
        "    for ll in lb:\n",
        "        if ll not in arr_labels:\n",
        "            arr_labels.add(ll)\n",
        "\n",
        "#말뭉치 데이터에 포함된 총 태그\n",
        "unique_labels = {'OGG_EDUCATION', 'MT_ELEMENT', 'AFW_OTHER_PRODUCTS', 'MT_ROCK', 'TI_OTHERS', 'PS_NAME', 'CV_BUILDING_TYPE', 'AM_REPTILIA', 'OGG_FOOD', 'AF_MUSICAL_INSTRUMENT', 'AF_BUILDING', 'AFA_MUSIC', 'CV_SPORTS_INST', 'QT_ORDER', 'TM_COLOR', 'LCG_MOUNTAIN', 'QT_MAN_COUNT', 'PS_CHARACTER', 'AM_OTHERS', 'OGG_LIBRARY', 'TMM_DISEASE', 'OGG_MEDICINE', 'LCG_ISLAND', 'TI_MINUTE', 'MT_CHEMICAL', 'TM_CELL_TISSUE_ORGAN', 'QT_OTHERS', 'CV_TRIBE', 'QT_TEMPERATURE', 'PT_FLOWER', 'OGG_POLITICS', 'DT_WEEK', 'FD_ART', 'AM_AMPHIBIA', 'FD_MEDICINE', 'AF_CULTURAL_ASSET', 'AF_TRANSPORT', 'EV_SPORTS', 'LCG_CONTINENT', 'PT_TREE', 'TMI_SERVICE', 'AM_MAMMALIA', 'TM_SPORTS', 'CV_INGREDIENT', 'OGG_HOTEL', 'QT_PHONE', 'CV_LANGUAGE', 'CV_FUNDS', 'CV_CURRENCY', 'FD_OTHERS', 'LCG_RIVER', 'LCP_CAPITALCITY', 'LC_OTHERS', 'QT_SIZE', 'TM_CLIMATE', 'TM_SHAPE', 'CV_POLICY', 'EV_ACTIVITY', 'TR_ART', 'QT_ADDRESS', 'OGG_RELIGION', 'CV_POSITION', 'FD_HUMANITIES', 'CV_CULTURE', 'QT_SPORTS', 'QT_ALBUM', 'CV_ART', 'CV_FOOD', 'CV_LAW', 'OGG_MILITARY', 'DT_DAY', 'FD_SOCIAL_SCIENCE', 'LCP_PROVINCE', 'CV_CLOTHING', 'TI_HOUR', 'DT_DYNASTY', 'DT_SEASON', 'FD_SCIENCE', 'TMI_HW', 'OGG_SPORTS', 'TR_OTHERS', 'TM_DIRECTION', 'TMI_SITE', 'QT_LENGTH', 'MT_METAL', 'LCG_OCEAN', 'DT_OTHERS', 'LCP_COUNTY', 'TMIG_GENRE', 'OGG_ECONOMY', 'TMI_SW', 'CV_SPORTS_POSITION', 'AFA_DOCUMENT', 'PT_OTHERS', 'AFA_ART_CRAFT', 'EV_OTHERS', 'TMI_EMAIL', 'QT_PRICE', 'EV_FESTIVAL', 'TI_SECOND', 'CV_TAX', 'O', 'QT_VOLUME', 'AF_WEAPON', 'LCG_BAY', 'OGG_SCIENCE', 'PT_FRUIT', 'CV_OCCUPATION', 'QT_CHANNEL', 'OGG_ART', 'AM_INSECT', 'CV_FOOD_STYLE', 'QT_PERCENTAGE', 'OGG_LAW', 'TR_SCIENCE', 'CV_RELATION', 'AM_PART', 'QT_AGE', 'TMI_MODEL', 'AM_BIRD', 'OGG_OTHERS', 'CV_SPORTS', 'DT_YEAR', 'LCP_COUNTRY', 'AFA_VIDEO', 'DT_GEOAGE', 'TI_DURATION', 'AM_TYPE', 'CV_SEASONING', 'AM_FISH', 'CV_PRIZE', 'PS_PET', 'AFW_SERVICE_PRODUCTS', 'TMI_PROJECT', 'CV_DRINK', 'LC_SPACE', 'LCP_CITY', 'EV_WAR_REVOLUTION', 'AFA_PERFORMANCE', 'QT_SPEED', 'PT_GRASS', 'DT_MONTH', 'PT_PART', 'OGG_MEDIA', 'PT_TYPE', 'TMM_DRUG', 'AF_ROAD', 'DT_DURATION', 'TR_MEDICINE', 'TR_HUMANITIES'}\n",
        "\n",
        "# Map each label into its id representation and vice versa\n",
        "labels_to_ids = {k: v for v, k in enumerate(sorted(unique_labels))}\n",
        "ids_to_labels = {v: k for v, k in enumerate(sorted(unique_labels))}\n",
        "\n",
        " #말뭉치에 포함되어 있지 않는 태그들 추가       \n",
        "labels_to_ids['CV_ACT'] = 150\n",
        "ids_to_labels[150] = 'CV_ACT'\n",
        "\n",
        "labels_to_ids['CV_STATE'] = 151\n",
        "ids_to_labels[151] = 'CV_STATE'\n",
        "\n",
        "print(ids_to_labels)\n",
        "print(len(ids_to_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look at how can we preprocess the text - Take first example\n",
        "text = df['text'].values.tolist()\n",
        "m_len = 0\n",
        "for t in text:\n",
        "    if m_len < len(t):\n",
        "        m_len = len(t)\n",
        "        \n",
        "example = text[1]\n",
        "\n",
        "print(example)\n",
        "print(m_len)"
      ],
      "metadata": {
        "id": "3IGRA-iG_cjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**4. 파인튜닝한 최종 모델과 토크나이저를 불러온다.**\n",
        "> ***모델, 토크나이저, epoch 입력/수정 필수!***\n",
        "\n"
      ],
      "metadata": {
        "id": "UOnkOhZZWSi4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "원하는 모델과 토크나이저를 불러오는 함수이다. \\\n",
        "\"/content/gdrive/MyDrive/2022_lesik_workspace/lesik/model/FIXED_FINAL_EPOCH_\"는 드라이브 내의 경로를 나타내는데, 왼쪽의 폴더 버튼을 눌러서 원하는 데이터의 경로를 확인할 수 있다.\n"
      ],
      "metadata": {
        "id": "bbs9xymmWlp9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4IhZVRfAWqn"
      },
      "outputs": [],
      "source": [
        "def load(epoch):\n",
        "    model_directory = '/content/gdrive/MyDrive/2022_lesik_workspace/lesik/model/FIXED_FINAL_EPOCH_'+ str(epoch) #모델 경로\n",
        "    model = ElectraForTokenClassification.from_pretrained(model_directory, num_labels=len(labels_to_ids))\n",
        "    model.to(device)\n",
        "    \n",
        "    tokenizer_directory = '/content/gdrive/MyDrive/2022_lesik_workspace/lesik/tokenizer/FIXED_FINAL_EPOCH_' +str(epoch) #토크나이저 경로\n",
        "    tokenizer = ElectraTokenizerFast.from_pretrained(tokenizer_directory)\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "argument로 불러오기를 원하는 epoch를 적는다."
      ],
      "metadata": {
        "id": "3JjzYNDANUwh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KB4kWc8C3Ws"
      },
      "outputs": [],
      "source": [
        "epoch = 72              #원하는 epoch로 변경\n",
        "model, tokenizer = load(epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5. 토큰화를 하기 위해 필요한 코드이다.**\n",
        "> ***원하는 epoch로 수정 가능!***"
      ],
      "metadata": {
        "id": "VGZyQqpxWytM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTy4INQtL4_S"
      },
      "source": [
        "epoch 개수는 고정이 아니므로 각 모델에 적절 또는 최적화 되어있는 개수로 변경하면 된다. \\\n",
        "(저희는 말뭉치 제외하고 72로 고정해서 학습) \\\n",
        "학습 중에 중단 되었을 경우, 저장된 epoch부터 이어서 학습 시킬 수 있다. 단, epochs를 저장된 epoch만큼 빼서 변경해줘야한다.\n",
        "> ex.) epoch 72를 목표하였고, epoch 48까지 저장된 후 중단 되었다면 \\\n",
        "72-48 = 24; epochs를 24로 변경해주면 된다. \n",
        "\n",
        "(8.학습 실행 코드 참고)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvnxXpk8C3W2"
      },
      "outputs": [],
      "source": [
        "from transformers import ElectraTokenizerFast\n",
        "\n",
        "MAX_LEN = 256\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "EPOCHS = 72             #원하는 epoch로 변경\n",
        "LEARNING_RATE = 1e-06\n",
        "MAX_GRAD_NORM = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpZ1jCnGC3XC"
      },
      "outputs": [],
      "source": [
        "class ElectraDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: get the sentence and word labels\n",
        "        sentence = self.data.text[index].strip() #문장 하나\n",
        "        word_labels = self.data.label[index].split() # 한 문장의 레이블들을 모아놓은 리스트\n",
        "\n",
        "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
        "        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
        "        encoding = self.tokenizer(sentence,\n",
        "                             return_offsets_mapping=True, \n",
        "                             padding='max_length', \n",
        "                             truncation=True, \n",
        "                             max_length=self.max_len)\n",
        "        valid_token_list = []\n",
        "        \n",
        "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
        "            if mapping[0] == 0 and mapping[1] == 0: #[cls]가 아니면\n",
        "                continue\n",
        "            valid_token_list.append(mapping)\n",
        "        if len(valid_token_list) != len(word_labels): \n",
        "            print(index, len(word_labels), len(valid_token_list), sentence)\n",
        "        \n",
        "        # step 3: create token labels only for first word pieces of each tokenized word\n",
        "        labels = [labels_to_ids[label] for label in word_labels] # 워드 레이블: 문장의 레이블을 모아놓은 리스트\n",
        "        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n",
        "        # create an empty array of -100 of length max_length\n",
        "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
        "        \n",
        "        # set only labels whose first offset position is 0 and the second is not 0\n",
        "        i = 0\n",
        "        if len(labels) != 0:\n",
        "            for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
        "                if mapping[0] == 0 and mapping[1] == 0: # [cls]가 아니면\n",
        "                    continue\n",
        "                tok = tokenizer.convert_ids_to_tokens(encoding['input_ids'][idx]) # 토큰이 저장됨\n",
        "            \n",
        "                # overwrite label\n",
        "                if i == len(labels):\n",
        "                    break\n",
        "                encoded_labels[idx] = labels[i] # 레이블 저장\n",
        "                i += 1           \n",
        "\n",
        "        # step 4: turn everything into PyTorch tensors\n",
        "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
        "        item['label'] = torch.as_tensor(encoded_labels)   \n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk3JvViRC3XE",
        "outputId": "01e4d377-9a76-435b-db0a-e091e7b24b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (5393, 2)\n",
            "TRAIN Dataset: (4314, 2)\n",
            "VALIDATION Dataset: (1079, 2)\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "train_size = 0.8\n",
        "train_dataset = df.sample(frac=train_size,random_state=200)\n",
        "validation_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape)) # 0.8\n",
        "print(\"VALIDATION Dataset: {}\".format(validation_dataset.shape)) # 0.2\n",
        "\n",
        "training_set = ElectraDataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = ElectraDataset(validation_dataset, tokenizer, MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Cv53qH97a8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f6ce978-07c0-4495-d71b-9271570663b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 4\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 4\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qO7lkEcVC3XL"
      },
      "outputs": [],
      "source": [
        "model.to(device) # cpu / gpu 사용 뭐 할지 선택 (꼭 필요!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knuKPJOiHbiZ",
        "outputId": "32432ca6-e4c9-4118-e03c-d6955419cc7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0477, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "inputs = training_set[2]\n",
        "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
        "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
        "labels = inputs[\"label\"].unsqueeze(0)\n",
        "\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inT7nrGIC3XN",
        "outputId": "cbe2a759-d669-4ef3-968a-c15fb14630f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 256, 152])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "tr_logits = outputs[1]\n",
        "tr_logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5oWYyUqC3XO"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "\n",
        "writer = SummaryWriter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDMEDa-1C3XQ"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**6. train, validation 함수를 불러오는 섹션이다.**"
      ],
      "metadata": {
        "id": "0qIdZJqGdIze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train을 위한 함수이다."
      ],
      "metadata": {
        "id": "9mvB0gwtbgS4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft-PEsUMC3XR"
      },
      "outputs": [],
      "source": [
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "    \n",
        "    for idx, batch in enumerate(training_loader):\n",
        "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "        labels = batch['label'].to(device, dtype = torch.long)\n",
        "\n",
        "        output = model(ids, attention_mask=mask, labels=labels)\n",
        "        loss = output[0]\n",
        "        tr_logits = output[1]\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += labels.size(0)\n",
        "        \n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
        "           \n",
        "        # compute training accuracy\n",
        "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.config.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        \n",
        "        # only compute accuracy at active labels\n",
        "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
        "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
        "        \n",
        "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "        \n",
        "        tr_labels.extend(labels)\n",
        "        tr_preds.extend(predictions)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "    \n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "        \n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
        "    writer.add_scalar('Train/Loss', epoch_loss, epoch)\n",
        "    writer.add_scalar('Train/Accuracy', tr_accuracy, epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "validation을 위한 함수이다."
      ],
      "metadata": {
        "id": "_fPKp4y2bmfZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YySwXwipC3XT"
      },
      "outputs": [],
      "source": [
        "def valid(epoch):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "            \n",
        "            ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "            labels = batch['label'].to(device, dtype = torch.long)\n",
        "            \n",
        "            output = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
        "            loss = output[0]\n",
        "            eval_logits = output[1]\n",
        "            \n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += labels.size(0)\n",
        "        \n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
        "              \n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.config.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            \n",
        "            # only compute accuracy at active labels\n",
        "            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
        "        \n",
        "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "            \n",
        "            eval_labels.extend(labels)\n",
        "            eval_preds.extend(predictions)\n",
        "            \n",
        "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
        "    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
        "    \n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "    writer.add_scalar('Validation/Loss', eval_loss, epoch)\n",
        "    writer.add_scalar('Validation/Accuracy', eval_accuracy, epoch)\n",
        "\n",
        "    return labels, predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**7. save 함수를 불러오는 섹션이다.**\n",
        "> ***directory/model/tokenizer 이름 변경은 필수!***"
      ],
      "metadata": {
        "id": "rBdxQnDmowAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 저장을 위한 함수이다."
      ],
      "metadata": {
        "id": "HE0sKIX3Qbv_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3nYYHRqC3XV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def save(epoch):\n",
        "    directory = \"/content/gdrive/MyDrive/2022_lesik_workspace/lesik/model/FTEST_EPOCH_\"+ str(epoch)\n",
        "    \n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    model.save_pretrained(directory)\n",
        "\n",
        "    torch.save(model.state_dict(), directory+\"/model.pt\")\n",
        "    directory = \"/content/gdrive/MyDrive/2022_lesik_workspace/lesik/tokenizer/FTEST_EPOCH_\" + str(epoch)\n",
        "    \n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    # save vocabulary of the tokenizer\n",
        "    tokenizer.save_vocabulary(directory)\n",
        "    tokenizer.save_pretrained(directory)\n",
        "    # save the model weights and its configuration file\n",
        "    print('All files saved')\n",
        "    print('This tutorial is completed')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**8. 학습을 실행하는 코드이다.**\n",
        "> ***학습 과정에서 끊겼을 경우, prev_epoch 변경 필수! 그 외는 0으로 실행!***"
      ],
      "metadata": {
        "id": "Khlzc34eeKSN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   prev_epoch는 학습을 시작하는 지점을 뜻하는 epoch이다.\n",
        "*   학습하다 끊겼을 경우, 저장 단위의 배수를 계산하여 마지막으로 저장된 epoch로 변경 해주면 된다. \\\n",
        "또한, 토큰화에서도 목표하고자 하는epoch를 저장된 epoch만큼 빼서 변경해줘야 한다.\n",
        "> ex.)epoch가 50에서 중단 되었을 경우, \\\n",
        "epoch 48까지 저장되었기 때문에 prev_epoch는 48로 시작. 토큰화의 epoch는 24로 변경. \\\n",
        "단, 51에서 중단되었을 경우, \\\n",
        "epoch 51이 저장되었다면, prev_epoch는 51부터 시작. 토큰화의 epoch는 21로 변경. \\\n",
        "epoch 51이 저장되지 않았다면,prev_epoch는 48부터 시작. 토큰화의 epoch는 24로 변경.\n",
        "*   epoch는 현재 3의 배수로 저장되고 있으며, 변경이 가능하다."
      ],
      "metadata": {
        "id": "_rRIDj-tiH-S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJbOtD9fYnN1",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "prev_epoch = 0          #학습을 시작하는 epoch\n",
        "for epoch in range(prev_epoch + 1, prev_epoch + 1 + EPOCHS):\n",
        "    print(f\"epoch: {epoch}\")\n",
        "    if epoch != 0 and epoch % 3 == 0: #현재 3의 배수로 저장되고 있으며 변경 가능 (3을 변경해주면 됩니다.)\n",
        "        save(epoch)\n",
        "    train(epoch)\n",
        "    labels, predictions = valid(epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(선택) 모델 학습 출력**\n",
        ">*** tensorboard 불러오기***"
      ],
      "metadata": {
        "id": "AgM5-Gz6Q1M_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WP479GGC3XX"
      },
      "outputs": [],
      "source": [
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 코드들을 실행하면 텐서보드를 작동시켜 그래프를 확인할 수 있다."
      ],
      "metadata": {
        "id": "IXvblDmCQCq9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "em2iKkc5u3y3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe52171f-6c4e-4f02-bc4e-aa6a67294154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir runs --port=6000"
      ],
      "metadata": {
        "id": "_-y_YCC8QtG9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "PyTorch 1.13 (NGC 22.05/Python 3.8 Conda) on Backend.AI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}