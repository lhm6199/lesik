{"cells":[{"cell_type":"markdown","source":["모델을 가장 처음에 학습하기 위한 코드이다. 이후에 파인튜닝을 진행할 시 태그를 더 추가할 수 없기 때문에 필요한 태그들은 아래 추가한 후 진행해야 된다. 이 코드는 gpu 사용량 때문에 colab에서 실행하지 못했고 backend ai를 사용했다."],"metadata":{"id":"q3EBR4IMioxs"}},{"cell_type":"markdown","source":["#**1. 학습을 위해 필요한 라이브러리를 불러온다.**"],"metadata":{"id":"Mi7vx64tzLDZ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QqEcaK7ky3o3","executionInfo":{"status":"ok","timestamp":1670991378456,"user_tz":-540,"elapsed":24514,"user":{"displayName":"소프트웨어학과/송지은","userId":"15070412098287679741"}},"outputId":"5d16baaa-b795-4a6c-9ed7-5b8e2f7003d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 11.7 MB/s \n","\u001b[?25hCollecting seqeval[gpu]\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.1 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 56.8 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 51.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval[gpu]) (1.0.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.7.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.2.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=2f459d7bd99be20af2234e8e315933c30b32fb076ecf2b2fc71af6040600b248\n","  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n","Successfully built seqeval\n","Installing collected packages: tokenizers, seqeval, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 seqeval-1.2.2 tokenizers-0.13.2 transformers-4.25.1\n"]}],"source":["!pip install transformers seqeval[gpu]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-hCoWlTpy3pH","executionInfo":{"status":"ok","timestamp":1670991381571,"user_tz":-540,"elapsed":3141,"user":{"displayName":"소프트웨어학과/송지은","userId":"15070412098287679741"}},"outputId":"03aa728f-4e8b-4c1e-94e2-bc3f776c48ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e4tOkol7y3pL"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import ElectraTokenizerFast, ElectraConfig, ElectraForTokenClassification"]},{"cell_type":"markdown","source":["#**2. 학습을 위한 데이터셋을 불러온다.**\n","> ***데이터의 경로 입력/수정 필수!***"],"metadata":{"id":"thexIUwfzXpT"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"sBiNy3EMy3pO","executionInfo":{"status":"ok","timestamp":1670991694463,"user_tz":-540,"elapsed":3042,"user":{"displayName":"소프트웨어학과/송지은","userId":"15070412098287679741"}},"outputId":"16500744-7bed-4f92-f1da-ee0054c55b9c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                text  \\\n","0  아~ 제목을 그냥 탄소 아~ 그리고 인간 원리 다중 우주 아~ 이런 제목을 잡았는데...   \n","1                            그니까 현대 우주론이 사실은 어디까지 왔나   \n","2                             그리고 현대 우주론의 딜레마가 무엇인가?   \n","3      아~ 그런 얘기를 이제 간략하게 다중 우주라는 키워드를 통해서 언급하려고 하고요.   \n","4  그 전에 어~ 어제 별을 보셨지만 저게 어~ 우리가 하늘을 바라볼 때 관찰하는 별들...   \n","\n","                                               label  \n","0  O O O O O MT_ELEMENT O O O O O O O O O O O O O...  \n","1        O O O TR_SCIENCE TR_SCIENCE O O O O O O O O  \n","2            O O TR_SCIENCE TR_SCIENCE O O O O O O O  \n","3  O O O O O O O O O TR_SCIENCE TR_SCIENCE O O O ...  \n","4  O O O O O DT_DAY O O O O O O O O O O O O O O O...  "],"text/html":["\n","  <div id=\"df-ac62d3e7-0bdb-46e1-94eb-3e9bfffe4a42\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>아~ 제목을 그냥 탄소 아~ 그리고 인간 원리 다중 우주 아~ 이런 제목을 잡았는데...</td>\n","      <td>O O O O O MT_ELEMENT O O O O O O O O O O O O O...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>그니까 현대 우주론이 사실은 어디까지 왔나</td>\n","      <td>O O O TR_SCIENCE TR_SCIENCE O O O O O O O O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>그리고 현대 우주론의 딜레마가 무엇인가?</td>\n","      <td>O O TR_SCIENCE TR_SCIENCE O O O O O O O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>아~ 그런 얘기를 이제 간략하게 다중 우주라는 키워드를 통해서 언급하려고 하고요.</td>\n","      <td>O O O O O O O O O TR_SCIENCE TR_SCIENCE O O O ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>그 전에 어~ 어제 별을 보셨지만 저게 어~ 우리가 하늘을 바라볼 때 관찰하는 별들...</td>\n","      <td>O O O O O DT_DAY O O O O O O O O O O O O O O O...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac62d3e7-0bdb-46e1-94eb-3e9bfffe4a42')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ac62d3e7-0bdb-46e1-94eb-3e9bfffe4a42 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ac62d3e7-0bdb-46e1-94eb-3e9bfffe4a42');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}],"source":["import pandas as pd\n","df = pd.read_csv('/home/work/lesik/data/modified_labeled_fixed_dataset.tsv', sep = '\\t', keep_default_na=False)\n","df.head()"]},{"cell_type":"markdown","source":["*   첫 학습 이후에 파인튜닝을 진행할 시 태그를 더 추가할 수 없기 때문에\n","fine_tuning과 test를 진행할 때는 무조건 태그가 동일해야 된다.\n","*   필요한 태그는 전부 아래 추가한 후 진행해야 된다."],"metadata":{"id":"Lp5uo5ajf-ja"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2183,"status":"ok","timestamp":1670991702268,"user":{"displayName":"소프트웨어학과/송지은","userId":"15070412098287679741"},"user_tz":-540},"id":"S_CDSb4AZ0C5","outputId":"72d623c2-8753-4b8a-bd13-77a6bc68a63c"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'OGG_HOTEL', 'TI_HOUR', 'QT_MAN_COUNT', 'AF_BUILDING', 'CV_POLICY', 'EV_FESTIVAL', 'AFA_ART_CRAFT', 'MT_CHEMICAL', 'QT_SPEED', 'O', 'LCP_CITY', 'OGG_EDUCATION', 'PT_FRUIT', 'QT_OTHERS', 'FD_ART', 'TR_OTHERS', 'AFW_OTHER_PRODUCTS', 'OGG_LAW', 'CV_PRIZE', 'LCG_MOUNTAIN', 'TMI_PROJECT', 'AFA_VIDEO', 'TR_HUMANITIES', 'CV_BUILDING_TYPE', 'MT_METAL', 'CV_SPORTS_INST', 'AFA_DOCUMENT', 'TMI_SW', 'PT_TYPE', 'TR_MEDICINE', 'PT_OTHERS', 'LCG_RIVER', 'LC_SPACE', 'OGG_SCIENCE', 'CV_SPORTS_POSITION', 'QT_SIZE', 'MT_ROCK', 'TMI_EMAIL', 'CV_CULTURE', 'TMI_SITE', 'AF_MUSICAL_INSTRUMENT', 'TI_MINUTE', 'CV_CLOTHING', 'AM_FISH', 'CV_FOOD_STYLE', 'OGG_MILITARY', 'TI_SECOND', 'AM_MAMMALIA', 'AM_INSECT', 'OGG_MEDIA', 'AFA_PERFORMANCE', 'TM_SPORTS', 'CV_DRINK', 'CV_ART', 'TM_CLIMATE', 'CV_LAW', 'DT_MONTH', 'QT_ORDER', 'CV_CURRENCY', 'AF_WEAPON', 'LCG_ISLAND', 'LCP_COUNTY', 'DT_YEAR', 'OGG_FOOD', 'OGG_ECONOMY', 'QT_TEMPERATURE', 'PS_CHARACTER', 'AM_PART', 'PT_TREE', 'CV_OCCUPATION', 'PS_NAME', 'QT_LENGTH', 'OGG_RELIGION', 'AF_ROAD', 'CV_FOOD', 'TMIG_GENRE', 'EV_OTHERS', 'OGG_OTHERS', 'TMI_SERVICE', 'FD_HUMANITIES', 'AF_TRANSPORT', 'TMM_DISEASE', 'TI_OTHERS', 'AM_TYPE', 'EV_WAR_REVOLUTION', 'TR_SCIENCE', 'DT_DAY', 'AM_BIRD', 'LCP_COUNTRY', 'PT_FLOWER', 'MT_ELEMENT', 'OGG_ART', 'FD_SOCIAL_SCIENCE', 'LCP_CAPITALCITY', 'TM_SHAPE', 'CV_LANGUAGE', 'DT_GEOAGE', 'QT_CHANNEL', 'FD_OTHERS', 'TMI_HW', 'CV_SPORTS', 'DT_SEASON', 'CV_POSITION', 'TMI_MODEL', 'TM_DIRECTION', 'LCG_CONTINENT', 'QT_PHONE', 'DT_DYNASTY', 'CV_INGREDIENT', 'OGG_MEDICINE', 'LCG_BAY', 'AFW_SERVICE_PRODUCTS', 'OGG_LIBRARY', 'CV_FUNDS', 'EV_SPORTS', 'AM_REPTILIA', 'QT_VOLUME', 'QT_PERCENTAGE', 'AM_AMPHIBIA', 'CV_RELATION', 'AF_CULTURAL_ASSET', 'CV_TRIBE', 'EV_ACTIVITY', 'FD_MEDICINE', 'PS_PET', 'QT_ALBUM', 'TMM_DRUG', 'LCP_PROVINCE', 'TI_DURATION', 'TM_CELL_TISSUE_ORGAN', 'PT_PART', 'OGG_SPORTS', 'DT_WEEK', 'LC_OTHERS', 'AFA_MUSIC', 'DT_OTHERS', 'PT_GRASS', 'TM_COLOR', 'TR_ART', 'AM_OTHERS', 'QT_PRICE', 'CV_SEASONING', 'QT_ADDRESS', 'FD_SCIENCE', 'OGG_POLITICS', 'QT_SPORTS', 'LCG_OCEAN', 'QT_AGE', 'CV_TAX', 'DT_DURATION'}\n","{'AFA_ART_CRAFT': 0, 'AFA_DOCUMENT': 1, 'AFA_MUSIC': 2, 'AFA_PERFORMANCE': 3, 'AFA_VIDEO': 4, 'AFW_OTHER_PRODUCTS': 5, 'AFW_SERVICE_PRODUCTS': 6, 'AF_BUILDING': 7, 'AF_CULTURAL_ASSET': 8, 'AF_MUSICAL_INSTRUMENT': 9, 'AF_ROAD': 10, 'AF_TRANSPORT': 11, 'AF_WEAPON': 12, 'AM_AMPHIBIA': 13, 'AM_BIRD': 14, 'AM_FISH': 15, 'AM_INSECT': 16, 'AM_MAMMALIA': 17, 'AM_OTHERS': 18, 'AM_PART': 19, 'AM_REPTILIA': 20, 'AM_TYPE': 21, 'CV_ART': 22, 'CV_BUILDING_TYPE': 23, 'CV_CLOTHING': 24, 'CV_CULTURE': 25, 'CV_CURRENCY': 26, 'CV_DRINK': 27, 'CV_FOOD': 28, 'CV_FOOD_STYLE': 29, 'CV_FUNDS': 30, 'CV_INGREDIENT': 31, 'CV_LANGUAGE': 32, 'CV_LAW': 33, 'CV_OCCUPATION': 34, 'CV_POLICY': 35, 'CV_POSITION': 36, 'CV_PRIZE': 37, 'CV_RELATION': 38, 'CV_SEASONING': 39, 'CV_SPORTS': 40, 'CV_SPORTS_INST': 41, 'CV_SPORTS_POSITION': 42, 'CV_TAX': 43, 'CV_TRIBE': 44, 'DT_DAY': 45, 'DT_DURATION': 46, 'DT_DYNASTY': 47, 'DT_GEOAGE': 48, 'DT_MONTH': 49, 'DT_OTHERS': 50, 'DT_SEASON': 51, 'DT_WEEK': 52, 'DT_YEAR': 53, 'EV_ACTIVITY': 54, 'EV_FESTIVAL': 55, 'EV_OTHERS': 56, 'EV_SPORTS': 57, 'EV_WAR_REVOLUTION': 58, 'FD_ART': 59, 'FD_HUMANITIES': 60, 'FD_MEDICINE': 61, 'FD_OTHERS': 62, 'FD_SCIENCE': 63, 'FD_SOCIAL_SCIENCE': 64, 'LCG_BAY': 65, 'LCG_CONTINENT': 66, 'LCG_ISLAND': 67, 'LCG_MOUNTAIN': 68, 'LCG_OCEAN': 69, 'LCG_RIVER': 70, 'LCP_CAPITALCITY': 71, 'LCP_CITY': 72, 'LCP_COUNTRY': 73, 'LCP_COUNTY': 74, 'LCP_PROVINCE': 75, 'LC_OTHERS': 76, 'LC_SPACE': 77, 'MT_CHEMICAL': 78, 'MT_ELEMENT': 79, 'MT_METAL': 80, 'MT_ROCK': 81, 'O': 82, 'OGG_ART': 83, 'OGG_ECONOMY': 84, 'OGG_EDUCATION': 85, 'OGG_FOOD': 86, 'OGG_HOTEL': 87, 'OGG_LAW': 88, 'OGG_LIBRARY': 89, 'OGG_MEDIA': 90, 'OGG_MEDICINE': 91, 'OGG_MILITARY': 92, 'OGG_OTHERS': 93, 'OGG_POLITICS': 94, 'OGG_RELIGION': 95, 'OGG_SCIENCE': 96, 'OGG_SPORTS': 97, 'PS_CHARACTER': 98, 'PS_NAME': 99, 'PS_PET': 100, 'PT_FLOWER': 101, 'PT_FRUIT': 102, 'PT_GRASS': 103, 'PT_OTHERS': 104, 'PT_PART': 105, 'PT_TREE': 106, 'PT_TYPE': 107, 'QT_ADDRESS': 108, 'QT_AGE': 109, 'QT_ALBUM': 110, 'QT_CHANNEL': 111, 'QT_LENGTH': 112, 'QT_MAN_COUNT': 113, 'QT_ORDER': 114, 'QT_OTHERS': 115, 'QT_PERCENTAGE': 116, 'QT_PHONE': 117, 'QT_PRICE': 118, 'QT_SIZE': 119, 'QT_SPEED': 120, 'QT_SPORTS': 121, 'QT_TEMPERATURE': 122, 'QT_VOLUME': 123, 'TI_DURATION': 124, 'TI_HOUR': 125, 'TI_MINUTE': 126, 'TI_OTHERS': 127, 'TI_SECOND': 128, 'TMIG_GENRE': 129, 'TMI_EMAIL': 130, 'TMI_HW': 131, 'TMI_MODEL': 132, 'TMI_PROJECT': 133, 'TMI_SERVICE': 134, 'TMI_SITE': 135, 'TMI_SW': 136, 'TMM_DISEASE': 137, 'TMM_DRUG': 138, 'TM_CELL_TISSUE_ORGAN': 139, 'TM_CLIMATE': 140, 'TM_COLOR': 141, 'TM_DIRECTION': 142, 'TM_SHAPE': 143, 'TM_SPORTS': 144, 'TR_ART': 145, 'TR_HUMANITIES': 146, 'TR_MEDICINE': 147, 'TR_OTHERS': 148, 'TR_SCIENCE': 149, 'CV_ACT': 150, 'CV_STATE': 151}\n","{0: 'AFA_ART_CRAFT', 1: 'AFA_DOCUMENT', 2: 'AFA_MUSIC', 3: 'AFA_PERFORMANCE', 4: 'AFA_VIDEO', 5: 'AFW_OTHER_PRODUCTS', 6: 'AFW_SERVICE_PRODUCTS', 7: 'AF_BUILDING', 8: 'AF_CULTURAL_ASSET', 9: 'AF_MUSICAL_INSTRUMENT', 10: 'AF_ROAD', 11: 'AF_TRANSPORT', 12: 'AF_WEAPON', 13: 'AM_AMPHIBIA', 14: 'AM_BIRD', 15: 'AM_FISH', 16: 'AM_INSECT', 17: 'AM_MAMMALIA', 18: 'AM_OTHERS', 19: 'AM_PART', 20: 'AM_REPTILIA', 21: 'AM_TYPE', 22: 'CV_ART', 23: 'CV_BUILDING_TYPE', 24: 'CV_CLOTHING', 25: 'CV_CULTURE', 26: 'CV_CURRENCY', 27: 'CV_DRINK', 28: 'CV_FOOD', 29: 'CV_FOOD_STYLE', 30: 'CV_FUNDS', 31: 'CV_INGREDIENT', 32: 'CV_LANGUAGE', 33: 'CV_LAW', 34: 'CV_OCCUPATION', 35: 'CV_POLICY', 36: 'CV_POSITION', 37: 'CV_PRIZE', 38: 'CV_RELATION', 39: 'CV_SEASONING', 40: 'CV_SPORTS', 41: 'CV_SPORTS_INST', 42: 'CV_SPORTS_POSITION', 43: 'CV_TAX', 44: 'CV_TRIBE', 45: 'DT_DAY', 46: 'DT_DURATION', 47: 'DT_DYNASTY', 48: 'DT_GEOAGE', 49: 'DT_MONTH', 50: 'DT_OTHERS', 51: 'DT_SEASON', 52: 'DT_WEEK', 53: 'DT_YEAR', 54: 'EV_ACTIVITY', 55: 'EV_FESTIVAL', 56: 'EV_OTHERS', 57: 'EV_SPORTS', 58: 'EV_WAR_REVOLUTION', 59: 'FD_ART', 60: 'FD_HUMANITIES', 61: 'FD_MEDICINE', 62: 'FD_OTHERS', 63: 'FD_SCIENCE', 64: 'FD_SOCIAL_SCIENCE', 65: 'LCG_BAY', 66: 'LCG_CONTINENT', 67: 'LCG_ISLAND', 68: 'LCG_MOUNTAIN', 69: 'LCG_OCEAN', 70: 'LCG_RIVER', 71: 'LCP_CAPITALCITY', 72: 'LCP_CITY', 73: 'LCP_COUNTRY', 74: 'LCP_COUNTY', 75: 'LCP_PROVINCE', 76: 'LC_OTHERS', 77: 'LC_SPACE', 78: 'MT_CHEMICAL', 79: 'MT_ELEMENT', 80: 'MT_METAL', 81: 'MT_ROCK', 82: 'O', 83: 'OGG_ART', 84: 'OGG_ECONOMY', 85: 'OGG_EDUCATION', 86: 'OGG_FOOD', 87: 'OGG_HOTEL', 88: 'OGG_LAW', 89: 'OGG_LIBRARY', 90: 'OGG_MEDIA', 91: 'OGG_MEDICINE', 92: 'OGG_MILITARY', 93: 'OGG_OTHERS', 94: 'OGG_POLITICS', 95: 'OGG_RELIGION', 96: 'OGG_SCIENCE', 97: 'OGG_SPORTS', 98: 'PS_CHARACTER', 99: 'PS_NAME', 100: 'PS_PET', 101: 'PT_FLOWER', 102: 'PT_FRUIT', 103: 'PT_GRASS', 104: 'PT_OTHERS', 105: 'PT_PART', 106: 'PT_TREE', 107: 'PT_TYPE', 108: 'QT_ADDRESS', 109: 'QT_AGE', 110: 'QT_ALBUM', 111: 'QT_CHANNEL', 112: 'QT_LENGTH', 113: 'QT_MAN_COUNT', 114: 'QT_ORDER', 115: 'QT_OTHERS', 116: 'QT_PERCENTAGE', 117: 'QT_PHONE', 118: 'QT_PRICE', 119: 'QT_SIZE', 120: 'QT_SPEED', 121: 'QT_SPORTS', 122: 'QT_TEMPERATURE', 123: 'QT_VOLUME', 124: 'TI_DURATION', 125: 'TI_HOUR', 126: 'TI_MINUTE', 127: 'TI_OTHERS', 128: 'TI_SECOND', 129: 'TMIG_GENRE', 130: 'TMI_EMAIL', 131: 'TMI_HW', 132: 'TMI_MODEL', 133: 'TMI_PROJECT', 134: 'TMI_SERVICE', 135: 'TMI_SITE', 136: 'TMI_SW', 137: 'TMM_DISEASE', 138: 'TMM_DRUG', 139: 'TM_CELL_TISSUE_ORGAN', 140: 'TM_CLIMATE', 141: 'TM_COLOR', 142: 'TM_DIRECTION', 143: 'TM_SHAPE', 144: 'TM_SPORTS', 145: 'TR_ART', 146: 'TR_HUMANITIES', 147: 'TR_MEDICINE', 148: 'TR_OTHERS', 149: 'TR_SCIENCE', 150: 'CV_ACT', 151: 'CV_STATE'}\n","152\n","152\n"]}],"source":["# Split labels based on whitespace and turn them into a list\n","labels = [i.split() for i in df['label'].values.tolist()]\n","\n","# Check how many labels are there in the dataset\n","#말뭉치 데이터에 포함된 총 태그\n","unique_labels = set()\n","for lb in labels:\n","  [unique_labels.add(i) for i in lb if i not in unique_labels]\n","\n","# Map each label into its id representation and vice versa\n","labels_to_ids = {k: v for v, k in enumerate(sorted(unique_labels))}\n","ids_to_labels = {v: k for v, k in enumerate(sorted(unique_labels))}\n","\n","#말뭉치에 포함되어 있지 않는 태그들 추가\n","labels_to_ids['CV_ACT'] = 150\n","ids_to_labels[150] = 'CV_ACT'\n","\n","labels_to_ids['CV_STATE'] = 151\n","ids_to_labels[151] = 'CV_STATE'\n","\n","print(ids_to_labels)\n","print(len(ids_to_labels))"]},{"cell_type":"code","source":["# Let's take a look at how can we preprocess the text - Take first example\n","text = df['text'].values.tolist()\n","m_len = 0\n","for t in text:\n","    if m_len < len(t):\n","        m_len = len(t)\n","        \n","example = text[1]\n","\n","print(example)\n","print(m_len)"],"metadata":{"id":"1f9grbm3ABlt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**3. koELECTRA 모델과 토크나이저를 불러온다.**"],"metadata":{"id":"O9luEhCw4X8-"}},{"cell_type":"code","source":["model = ElectraForTokenClassification.from_pretrained(\"monologg/koelectra-small-v2-discriminator\", num_labels=len(labels_to_ids))\n","model.to(device)\n","tokenizer = ElectraTokenizerFast.from_pretrained('monologg/koelectra-small-v2-discriminator')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":188,"referenced_widgets":["c9f35732c18e49b9a77931af47f505bf","d0dcb141ef584fd78924da45e18c4659","4c86e503c18a4d68972ac880487163d2","99aecb5a8f164b55a213d9e9d41c65c5","9980571ba7f0458eada1a5d870d56335","69ba1d85a1384f52ac3e2a072edd45b4","d65262b2fd214edab77dd9896e4e0e0d","8fd486b71b6d4b01b257ea3c34d9f965","ad93397c4bdd4793a9c7eb197c57a922","0db90342311743bc976c6192723698f9","7b3ab90e34054c1899ae1a35429878ee"]},"id":"DCxaWqRp3mH6","executionInfo":{"status":"ok","timestamp":1670991773937,"user_tz":-540,"elapsed":10364,"user":{"displayName":"소프트웨어학과/송지은","userId":"15070412098287679741"}},"outputId":"2974b850-998c-4719-a9e0-5f55807922eb"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/55.1M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9f35732c18e49b9a77931af47f505bf"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at monologg/koelectra-small-v2-discriminator were not used when initializing ElectraForTokenClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight']\n","- This IS expected if you are initializing ElectraForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForTokenClassification were not initialized from the model checkpoint at monologg/koelectra-small-v2-discriminator and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","source":["#**4. 토큰화를 하기 위해 필요한 코드이다.**\n","> ***원하는 epoch로 수정 가능!***"],"metadata":{"id":"ssiYrVYFz7gN"}},{"cell_type":"markdown","source":["epoch 개수는 고정이 아니므로 각 모델에 적절 또는 최적화 되어있는 개수로 변경하면 된다. \\\n","학습 중에 중단 되었을 경우, 저장된 epoch부터 이어서 학습 시킬 수 있다. 단, epochs를 저장된 epoch만큼 빼서 변경해줘야한다.\n","> ex.) epoch 72를 목표하였고, epoch 48까지 저장된 후 중단 되었다면 \\\n","72-48 = 24; epochs를 24로 변경해주면 된다. \n","\n","(7.학습 실행 코드 참고)"],"metadata":{"id":"JaRuvh-f1FCd"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"E30tOyaRy3pe"},"outputs":[],"source":["from transformers import ElectraTokenizerFast\n","\n","MAX_LEN = 256\n","TRAIN_BATCH_SIZE = 64\n","VALID_BATCH_SIZE = 64\n","EPOCHS = 72\n","LEARNING_RATE = 1e-05\n","MAX_GRAD_NORM = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0lNxqhTVy3pn"},"outputs":[],"source":["class ElectraDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __getitem__(self, index):\n","        # step 1: get the sentence and word labels \n","        sentence = self.data.text[index].strip()\n","        word_labels = self.data.label[index].split()\n","\n","        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n","        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n","        encoding = self.tokenizer(sentence,\n","                             return_offsets_mapping=True, \n","                             padding='max_length', \n","                             truncation=True, \n","                             max_length=self.max_len)\n","        \n","        valid_token_list = []\n","        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n","            if mapping[0] == 0 and mapping[1] == 0:\n","                continue\n","            valid_token_list.append(mapping)\n","        if len(valid_token_list) != len(word_labels):\n","            print(index, len(word_labels), len(valid_token_list), sentence)\n","        \n","        # step 3: create token labels only for first word pieces of each tokenized word\n","        labels = [labels_to_ids[label] for label in word_labels] \n","        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n","        # create an empty array of -100 of length max_length\n","        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n","        \n","        # set only labels whose first offset position is 0 and the second is not 0\n","        i = 0\n","        if len(labels) != 0:\n","            for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n","                if mapping[0] == 0 and mapping[1] == 0:\n","                    continue\n","                tok = tokenizer.convert_ids_to_tokens(encoding['input_ids'][idx])\n","            \n","                # overwrite label\n","                if i == len(labels):\n","                    break\n","                encoded_labels[idx] = labels[i]\n","                i += 1\n","                \n","        # step 4: turn everything into PyTorch tensors\n","        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","        item['label'] = torch.as_tensor(encoded_labels)\n","        \n","        return item\n","    def __len__(self):\n","        return self.len"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HEgjXwJHy3px","executionInfo":{"status":"ok","timestamp":1670991785865,"user_tz":-540,"elapsed":21,"user":{"displayName":"소프트웨어학과/송지은","userId":"15070412098287679741"}},"outputId":"c8452003-fa94-4b59-ba91-6d2deed42bf7"},"outputs":[{"output_type":"stream","name":"stdout","text":["FULL Dataset: (356504, 2)\n","TRAIN Dataset: (285203, 2)\n","TEST Dataset: (71301, 2)\n"]}],"source":["train_size = 0.8\n","train_dataset = df.sample(frac=train_size,random_state=200)\n","test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n","train_dataset = train_dataset.reset_index(drop=True)\n","\n","print(\"FULL Dataset: {}\".format(df.shape))\n","print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","print(\"TEST Dataset: {}\".format(test_dataset.shape))\n","\n","training_set = ElectraDataset(train_dataset, tokenizer, MAX_LEN)\n","testing_set = ElectraDataset(test_dataset, tokenizer, MAX_LEN)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1670991787345,"user":{"displayName":"소프트웨어학과/송지은","userId":"15070412098287679741"},"user_tz":-540},"id":"8Cv53qH97a8P","colab":{"base_uri":"https://localhost:8080/"},"outputId":"70b1af5e-5613-4f02-d8d5-3a7a73f4e224"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 4\n","                }\n","\n","test_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 4\n","                }\n","\n","training_loader = DataLoader(training_set, **train_params)\n","testing_loader = DataLoader(testing_set, **test_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3333,"status":"ok","timestamp":1670991792522,"user":{"displayName":"소프트웨어학과/송지은","userId":"15070412098287679741"},"user_tz":-540},"id":"knuKPJOiHbiZ","outputId":"48c65dbc-9102-4907-90c5-4f2cf0382f7a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(4.9279, device='cuda:0', grad_fn=<NllLossBackward0>)"]},"metadata":{},"execution_count":15}],"source":["inputs = training_set[2]\n","input_ids = inputs[\"input_ids\"].unsqueeze(0)\n","attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n","labels = inputs[\"label\"].unsqueeze(0)\n","\n","input_ids = input_ids.to(device)\n","attention_mask = attention_mask.to(device)\n","labels = labels.to(device)\n","\n","outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","initial_loss = outputs[0]\n","initial_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qTG-OFbTy3p_","executionInfo":{"status":"ok","timestamp":1670991792526,"user_tz":-540,"elapsed":55,"user":{"displayName":"소프트웨어학과/송지은","userId":"15070412098287679741"}},"outputId":"55b9caa8-79ac-485c-f355-1ca6e01ed138"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 256, 152])"]},"metadata":{},"execution_count":16}],"source":["tr_logits = outputs[1]\n","tr_logits.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ezwpwVzvy3qB","executionInfo":{"status":"ok","timestamp":1670991806811,"user_tz":-540,"elapsed":4366,"user":{"displayName":"소프트웨어학과/송지은","userId":"15070412098287679741"}},"outputId":"990ba633-3735-41e1-d1eb-8db2ce136a16"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 13.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.5.1\n"]}],"source":["!pip install tensorboardX\n","\n","from tensorboardX import SummaryWriter\n","writer = SummaryWriter()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6nfu7m9Zy3qC"},"outputs":[],"source":["optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"]},{"cell_type":"markdown","source":["#**5. train, validation 함수를 불러오는 섹션이다.**"],"metadata":{"id":"8JPHdIBi4tp5"}},{"cell_type":"markdown","source":["train을 위한 함수이다."],"metadata":{"id":"FAWjl3V54xQJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"W7KR_p-ky3qE"},"outputs":[],"source":["# Defining the training function on the 80% of the dataset for tuning the bert model\n","def train(epoch):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    # put model in training mode\n","    model.train()\n","    \n","    for idx, batch in enumerate(training_loader):\n","        ids = batch['input_ids'].to(device, dtype = torch.long)\n","        mask = batch['attention_mask'].to(device, dtype = torch.long)\n","        labels = batch['label'].to(device, dtype = torch.long)\n","\n","        output = model(ids, attention_mask=mask, labels=labels)\n","        loss = output[0]\n","        tr_logits = output[1]\n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += labels.size(0)\n","        \n","        if idx % 100==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss per 100 training steps: {loss_step}\")\n","           \n","        # compute training accuracy\n","        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","        active_logits = tr_logits.view(-1, model.config.num_labels) # shape (batch_size * seq_len, num_labels)\n","        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","        \n","        # only compute accuracy at active labels\n","        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","        \n","        labels = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","        \n","        tr_labels.extend(labels)\n","        tr_preds.extend(predictions)\n","\n","        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","        tr_accuracy += tmp_tr_accuracy\n","    \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","        \n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","    print(f\"Training loss epoch: {epoch_loss}\")\n","    print(f\"Training accuracy epoch: {tr_accuracy}\")\n","    writer.add_scalar('Train/Loss', epoch_loss, epoch)\n","    writer.add_scalar('Train/Accuracy', tr_accuracy, epoch)\n","    "]},{"cell_type":"markdown","source":["validation을 위한 함수이다."],"metadata":{"id":"BCKepAG841Qv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kTx-ZhcSy3qJ"},"outputs":[],"source":["def valid(epoch):\n","    # put model in evaluation mode\n","    model.eval()\n","    \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(testing_loader):\n","            \n","            ids = batch['input_ids'].to(device, dtype = torch.long)\n","            mask = batch['attention_mask'].to(device, dtype = torch.long)\n","            labels = batch['label'].to(device, dtype = torch.long)\n","            \n","            output = model(input_ids=ids, attention_mask=mask, labels=labels)\n","            loss = output[0]\n","            eval_logits = output[1]\n","            \n","            eval_loss += loss.item()\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += labels.size(0)\n","        \n","            if idx % 100==0:\n","                loss_step = eval_loss/nb_eval_steps\n","                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n","              \n","            # compute evaluation accuracy\n","            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","            active_logits = eval_logits.view(-1, model.config.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","            \n","            # only compute accuracy at active labels\n","            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        \n","            labels = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","            \n","            eval_labels.extend(labels)\n","            eval_preds.extend(predictions)\n","            \n","            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","            eval_accuracy += tmp_eval_accuracy\n","\n","    labels = [ids_to_labels[id.item()] for id in eval_labels]\n","    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n","    \n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_steps\n","    print(f\"Validation Loss: {eval_loss}\")\n","    print(f\"Validation Accuracy: {eval_accuracy}\")\n","    writer.add_scalar('Validation/Loss', eval_loss, epoch)\n","    writer.add_scalar('Validation/Accuracy', eval_accuracy, epoch)\n","\n","    return labels, predictions"]},{"cell_type":"markdown","source":["#**6. save 함수를 불러오는 섹션이다.**\n","> ***directory/model/tokenizer 이름 변경은 필수!***"],"metadata":{"id":"S_4B-3dS45yn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"54bGkXaCy3qP"},"outputs":[],"source":["import os\n","def save(epoch):\n","    directory = \"/home/work/lesik/model/FIXED_EPOCH_\"+str(epoch)\n","\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)\n","    model.save_pretrained(directory)\n","\n","    torch.save(model.state_dict(), directory+\"/model.pt\")\n","    directory = \"/home/work/lesik/tokenizer/FIXED_EPOCH_\" + str(epoch)\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)\n","    # save vocabulary of the tokenizer\n","    tokenizer.save_vocabulary(directory)\n","    tokenizer.save_pretrained(directory)\n","    # save the model weights and its configuration file\n","    print('All files saved')\n","    print('This tutorial is completed')"]},{"cell_type":"markdown","source":["#**7. 학습을 실행하는 코드이다.**\n","> ***학습 과정에서 끊겼을 경우, prev_epoch 변경 필수! 그 외는 0으로 실행!***"],"metadata":{"id":"abKjYSNQ5fmO"}},{"cell_type":"markdown","source":["\n","*   prev_epoch는 학습을 시작하는 지점을 뜻하는 epoch이다.\n","*   학습하다 끊겼을 경우, 저장 단위의 배수를 계산하여 마지막으로 저장된 epoch로 변경 해주면 된다. \\\n","또한, 토큰화에서도 목표하고자 하는epoch를 저장된 epoch만큼 빼서 변경해줘야 한다.\n","> ex.)epoch가 50에서 중단 되었을 경우, \\\n","epoch 48까지 저장되었기 때문에 prev_epoch는 48로 시작. 토큰화의 epoch는 24로 변경. \\\n","단, 51에서 중단되었을 경우, \\\n","epoch 51이 저장되었다면, prev_epoch는 51부터 시작. 토큰화의 epoch는 21로 변경. \\\n","epoch 51이 저장되지 않았다면,prev_epoch는 48부터 시작. 토큰화의 epoch는 24로 변경.\n","*   epoch는 현재 3의 배수로 저장되고 있으며, 변경이 가능하다."],"metadata":{"id":"zoH1Uw-M5nMw"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":250860,"status":"error","timestamp":1670992151964,"user":{"displayName":"소프트웨어학과/송지은","userId":"15070412098287679741"},"user_tz":-540},"id":"cJbOtD9fYnN1","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"afe77fef-cd96-4287-a1ea-5701497ca9fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Training loss per 100 training steps: 4.74533224105835\n","Training loss per 100 training steps: 3.736000901401633\n","Training loss per 100 training steps: 3.310012743840763\n","Training loss per 100 training steps: 3.085151396716552\n","Training loss per 100 training steps: 2.9270929267578887\n","Training loss per 100 training steps: 2.798927214807141\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-23-c21357dbc8f3>\", line 4, in <module>\n","    train(epoch)\n","  File \"<ipython-input-19-c25f3af8c943>\", line 51, in train\n","    loss.backward()\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 487, in backward\n","    torch.autograd.backward(\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 197, in backward\n","    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 319, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.8/inspect.py\", line 708, in getsourcefile\n","    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n","  File \"/usr/lib/python3.8/inspect.py\", line 754, in getmodule\n","    os.path.realpath(f)] = module.__name__\n","  File \"/usr/lib/python3.8/posixpath.py\", line 391, in realpath\n","    path, ok = _joinrealpath(filename[:0], filename, {})\n","  File \"/usr/lib/python3.8/posixpath.py\", line 424, in _joinrealpath\n","    newpath = join(path, name)\n","  File \"/usr/lib/python3.8/posixpath.py\", line 85, in join\n","    elif not path or path.endswith(sep):\n","KeyboardInterrupt\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"]}],"source":["prev_epoch = 0                   #학습을 시작하는 epoch\n","for epoch in range(prev_epoch + 1, prev_epoch + 1 + EPOCHS):\n","    print(f\"epoch: {epoch}\")\n","    train(epoch)\n","    valid(epoch)\n","    if epoch != 0 and epoch % 3 == 0:     #현재 3의 배수로 저장되고 있으며 변경 가능 (3을 변경해주면 됩니다.)\n","        save(epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vmlstB95y3qW"},"outputs":[],"source":["writer.close()"]}],"metadata":{"colab":{"provenance":[{"file_id":"1GsDbxka0nsk8ybzfGo3WkgGkyLfhofzE","timestamp":1658803992993},{"file_id":"1mjk2Nzdm__GnSUcjiJCAGeEWVeS7B9tl","timestamp":1658414474037}]},"gpuClass":"standard","kernelspec":{"display_name":"PyTorch 1.13 (NGC 22.05/Python 3.8 Conda) on Backend.AI","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c9f35732c18e49b9a77931af47f505bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d0dcb141ef584fd78924da45e18c4659","IPY_MODEL_4c86e503c18a4d68972ac880487163d2","IPY_MODEL_99aecb5a8f164b55a213d9e9d41c65c5"],"layout":"IPY_MODEL_9980571ba7f0458eada1a5d870d56335"}},"d0dcb141ef584fd78924da45e18c4659":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69ba1d85a1384f52ac3e2a072edd45b4","placeholder":"​","style":"IPY_MODEL_d65262b2fd214edab77dd9896e4e0e0d","value":"Downloading: 100%"}},"4c86e503c18a4d68972ac880487163d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fd486b71b6d4b01b257ea3c34d9f965","max":55102451,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad93397c4bdd4793a9c7eb197c57a922","value":55102451}},"99aecb5a8f164b55a213d9e9d41c65c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0db90342311743bc976c6192723698f9","placeholder":"​","style":"IPY_MODEL_7b3ab90e34054c1899ae1a35429878ee","value":" 55.1M/55.1M [00:01&lt;00:00, 43.5MB/s]"}},"9980571ba7f0458eada1a5d870d56335":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69ba1d85a1384f52ac3e2a072edd45b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d65262b2fd214edab77dd9896e4e0e0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fd486b71b6d4b01b257ea3c34d9f965":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad93397c4bdd4793a9c7eb197c57a922":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0db90342311743bc976c6192723698f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b3ab90e34054c1899ae1a35429878ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}